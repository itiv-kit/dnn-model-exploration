{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oq4116/virtualenvs/torch_quantization/lib64/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pymoo.core.result.Result"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import io\n",
    "\n",
    "from src.quantization.quantized_model import QuantizedModel\n",
    "from src.exploration.problems import LayerwiseQuantizationProblem\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "\n",
    "with open('../results/exploration_resnet18_imagenet_2022-11-08_13-46-00.pkl', 'rb') as f:\n",
    "    d = CPU_Unpickler(f).load()\n",
    "\n",
    "type(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(d.problem.min_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy_bound = d.problem.min_accuracy\n",
    "shape_x = d.problem.n_obj + d.problem.n_constr + d.problem.n_var\n",
    "\n",
    "all_individuals = np.ndarray( (0, shape_x) )\n",
    "\n",
    "for h in d.history:\n",
    "    for ind in h.opt:\n",
    "        individual_row = np.concatenate( (ind.get(\"G\") - accuracy_bound, ind.get(\"F\"), ind.get(\"X\")) )\n",
    "        individual_row = np.expand_dims(individual_row, axis=0)\n",
    "        all_individuals = np.concatenate( (all_individuals, individual_row), axis=0)\n",
    "        \n",
    "df = pd.DataFrame(all_individuals)\n",
    "df[0] = -df[0] # invert Accuracy\n",
    "df_fit = df.where(df[0] > accuracy_bound) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1      2    3     4     5     6     7     8     9   ...  \\\n",
      "0         NaN       NaN    NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1    0.702881 -0.702881  473.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
      "2    0.702881 -0.702881  473.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
      "3    0.703003 -0.703003  489.0  6.0  12.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
      "4    0.733032 -0.733032  491.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
      "..        ...       ...    ...  ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "132  0.734009 -0.734009  415.0  9.0  11.0  10.0   8.0  12.0   8.0  14.0  ...   \n",
      "133  0.738159 -0.738159  446.0  9.0  11.0  10.0   8.0  12.0  12.0  14.0  ...   \n",
      "134  0.727539 -0.727539  409.0  9.0  12.0  10.0   8.0  12.0   8.0  14.0  ...   \n",
      "135  0.735107 -0.735107  439.0  9.0  11.0  10.0   8.0  12.0  12.0  14.0  ...   \n",
      "136  0.727051 -0.727051  404.0  9.0  11.0   8.0   8.0  11.0   8.0  14.0  ...   \n",
      "\n",
      "       36    37    38    39    40    41    42    43    44    45  \n",
      "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "1    13.0  10.0  12.0   7.0  10.0   7.0   3.0  16.0   5.0  13.0  \n",
      "2    13.0  10.0  12.0   7.0  10.0   7.0   3.0  16.0   5.0  13.0  \n",
      "3    13.0  10.0   9.0  15.0   3.0  10.0  13.0  16.0  14.0  14.0  \n",
      "4    13.0  10.0  12.0   7.0  10.0   9.0   6.0  16.0   7.0  13.0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "132  13.0  10.0   7.0   6.0  10.0   7.0   4.0  15.0   7.0  13.0  \n",
      "133  13.0  10.0  12.0   7.0  10.0   7.0   6.0  15.0   7.0  13.0  \n",
      "134  13.0  10.0   7.0   6.0  10.0   7.0   4.0  15.0   7.0  13.0  \n",
      "135  13.0  10.0  12.0   6.0  10.0   7.0   4.0  15.0   7.0  13.0  \n",
      "136  13.0  10.0   7.0   6.0  10.0   7.0   4.0  15.0   7.0  13.0  \n",
      "\n",
      "[137 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.738159</td>\n",
       "      <td>-0.738159</td>\n",
       "      <td>446.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.738159</td>\n",
       "      <td>-0.738159</td>\n",
       "      <td>446.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.737671</td>\n",
       "      <td>-0.737671</td>\n",
       "      <td>485.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.737671</td>\n",
       "      <td>-0.737671</td>\n",
       "      <td>485.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.737671</td>\n",
       "      <td>-0.737671</td>\n",
       "      <td>485.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.702026</td>\n",
       "      <td>-0.702026</td>\n",
       "      <td>411.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.701294</td>\n",
       "      <td>-0.701294</td>\n",
       "      <td>411.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.701294</td>\n",
       "      <td>-0.701294</td>\n",
       "      <td>411.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.700684</td>\n",
       "      <td>-0.700684</td>\n",
       "      <td>408.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655151</td>\n",
       "      <td>-0.655151</td>\n",
       "      <td>421.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1      2    3     4     5     6     7     8     9   ...  \\\n",
       "133  0.738159 -0.738159  446.0  9.0  11.0  10.0   8.0  12.0  12.0  14.0  ...   \n",
       "128  0.738159 -0.738159  446.0  9.0  11.0  10.0   8.0  12.0  12.0  14.0  ...   \n",
       "94   0.737671 -0.737671  485.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
       "101  0.737671 -0.737671  485.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
       "109  0.737671 -0.737671  485.0  9.0  15.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
       "..        ...       ...    ...  ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "75   0.702026 -0.702026  411.0  9.0  12.0  10.0   8.0  11.0   8.0  14.0  ...   \n",
       "55   0.701294 -0.701294  411.0  9.0  12.0  10.0   8.0  11.0   8.0  14.0  ...   \n",
       "62   0.701294 -0.701294  411.0  9.0  12.0  10.0   8.0  11.0   8.0  14.0  ...   \n",
       "103  0.700684 -0.700684  408.0  9.0  12.0  10.0   8.0  10.0   8.0  14.0  ...   \n",
       "0    0.655151 -0.655151  421.0  6.0  10.0  13.0  14.0  13.0  12.0  14.0  ...   \n",
       "\n",
       "       36    37    38   39    40   41    42    43   44    45  \n",
       "133  13.0  10.0  12.0  7.0  10.0  7.0   6.0  15.0  7.0  13.0  \n",
       "128  13.0  10.0  12.0  7.0  10.0  7.0   6.0  15.0  7.0  13.0  \n",
       "94   13.0  10.0  12.0  7.0  10.0  9.0  16.0  16.0  7.0  13.0  \n",
       "101  13.0  10.0  12.0  7.0  10.0  9.0  16.0  16.0  7.0  13.0  \n",
       "109  13.0  10.0  12.0  7.0  10.0  9.0  16.0  16.0  7.0  13.0  \n",
       "..    ...   ...   ...  ...   ...  ...   ...   ...  ...   ...  \n",
       "75   13.0  10.0   7.0  6.0  10.0  7.0   3.0  15.0  7.0  13.0  \n",
       "55   13.0  10.0   7.0  6.0  10.0  7.0   3.0  15.0  7.0  13.0  \n",
       "62   13.0  10.0   7.0  6.0  10.0  7.0   3.0  15.0  7.0  13.0  \n",
       "103  13.0  10.0   7.0  6.0  10.0  7.0   3.0  15.0  7.0  13.0  \n",
       "0    13.0  10.0   9.0  7.0   3.0  7.0   3.0  16.0  5.0  13.0  \n",
       "\n",
       "[137 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import webdataset as wds\n",
    "\n",
    "def identity(d):\n",
    "    return d\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transf = transforms.Compose([transforms.Resize(256),\n",
    "                            transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(),\n",
    "                            normalize])\n",
    "\n",
    "train_path = '/tools/datasets/imagenet/train/imagenet-train-{0000..0136}.tar'\n",
    "\n",
    "dataset_load = (\n",
    "    wds.WebDataset(train_path, shardshuffle=True)\n",
    "    .decode(\"pil\")\n",
    "    .to_tuple(\"input.jpeg\", \"target.cls\")\n",
    "    .shuffle(10000)\n",
    "    .map_tuple(transf, identity)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_load))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'webdataset.compat.WebDataset'>\n",
      "tensor([[[ 78, 121, 265,  ..., 914, 914, 265],\n",
      "         [121, 121, 774,  ..., 121, 265, 774],\n",
      "         [121, 265, 121,  ..., 121, 121, 121],\n",
      "         ...,\n",
      "         [265, 774, 265,  ..., 914,  78, 265],\n",
      "         [914, 914, 152,  ..., 265, 265, 265],\n",
      "         [121, 774, 914,  ..., 914, 121, 774]],\n",
      "\n",
      "        [[143, 680, 674,  ..., 674, 927, 830],\n",
      "         [ 41, 618, 456,  ...,  69, 674,  69],\n",
      "         [401, 703, 383,  ..., 618, 830, 638],\n",
      "         ...,\n",
      "         [927, 638, 680,  ..., 674, 830, 835],\n",
      "         [680,  41, 680,  ..., 674, 680, 703],\n",
      "         [674, 456, 349,  ..., 383, 830, 680]],\n",
      "\n",
      "        [[ 84, 461, 602,  ..., 934, 602, 265],\n",
      "         [509, 823, 265,  ..., 461, 573, 602],\n",
      "         [774, 854, 956,  ..., 823, 461, 509],\n",
      "         ...,\n",
      "         [914, 774, 509,  ..., 934, 461, 823],\n",
      "         [509, 461, 823,  ..., 368, 121, 573],\n",
      "         [854,  78, 461,  ..., 398, 774, 368]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[956, 854, 602,  ..., 774, 886, 823],\n",
      "         [368, 602, 461,  ..., 573, 886, 602],\n",
      "         [823, 956,  84,  ..., 602, 854, 914],\n",
      "         ...,\n",
      "         [823, 368, 854,  ..., 854, 461, 602],\n",
      "         [265, 934, 573,  ..., 461, 573, 886],\n",
      "         [398, 509, 823,  ..., 823, 956, 573]],\n",
      "\n",
      "        [[774, 886, 956,  ..., 573, 774, 628],\n",
      "         [854, 602, 368,  ..., 573, 854, 602],\n",
      "         [628, 854, 461,  ..., 602, 368, 886],\n",
      "         ...,\n",
      "         [573, 956, 461,  ..., 602, 265, 956],\n",
      "         [934, 823, 461,  ..., 994, 628, 994],\n",
      "         [602, 854, 398,  ..., 956, 956, 994]],\n",
      "\n",
      "        [[398, 265, 461,  ..., 956, 368, 476],\n",
      "         [602, 602, 368,  ..., 461, 476, 121],\n",
      "         [573, 934, 956,  ..., 461, 509, 854],\n",
      "         ...,\n",
      "         [854, 509, 398,  ..., 509, 854, 823],\n",
      "         [602, 509, 823,  ..., 854, 914, 573],\n",
      "         [602, 461, 573,  ..., 509, 398, 602]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(type(dataset_load))\n",
    "dataset_load = dataset_load.batched(16)\n",
    "\n",
    "loader = wds.WebLoader(dataset_load, num_workers=2, batch_size=None)\n",
    "loader = loader.unbatched().shuffle(1000).batched(16)\n",
    "# loader = DataLoader(dataset_load, num_workers=2, batch_size=16)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(batch[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('torch_quantization')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13163a71fd25ca99df19113b0b7fef1658e8dabbe29c7565da80e947514db9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
