{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ResNet                                             [1, 1000]                 --\n",
       "├─QuantConv2d: 1-1                                 [1, 64, 112, 112]         9,408\n",
       "│    └─TensorQuantizer: 2-1                        [1, 3, 224, 224]          --\n",
       "│    └─TensorQuantizer: 2-2                        [64, 3, 7, 7]             --\n",
       "├─BatchNorm2d: 1-2                                 [1, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                                        [1, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                                   [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                                  [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-3                             [1, 256, 56, 56]          --\n",
       "│    │    └─QuantConv2d: 3-1                       [1, 64, 56, 56]           4,096\n",
       "│    │    └─BatchNorm2d: 3-2                       [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-3                              [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-4                       [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5                       [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-6                              [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-7                       [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-8                       [1, 256, 56, 56]          512\n",
       "│    │    └─Sequential: 3-9                        [1, 256, 56, 56]          16,896\n",
       "│    │    └─ReLU: 3-10                             [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-4                             [1, 256, 56, 56]          --\n",
       "│    │    └─QuantConv2d: 3-11                      [1, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-12                      [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-13                             [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-14                      [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-15                      [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-16                             [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-17                      [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-18                      [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-19                             [1, 256, 56, 56]          --\n",
       "│    └─Bottleneck: 2-5                             [1, 256, 56, 56]          --\n",
       "│    │    └─QuantConv2d: 3-20                      [1, 64, 56, 56]           16,384\n",
       "│    │    └─BatchNorm2d: 3-21                      [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-22                             [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-23                      [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-24                      [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-25                             [1, 64, 56, 56]           --\n",
       "│    │    └─QuantConv2d: 3-26                      [1, 256, 56, 56]          16,384\n",
       "│    │    └─BatchNorm2d: 3-27                      [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-28                             [1, 256, 56, 56]          --\n",
       "├─Sequential: 1-6                                  [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-6                             [1, 512, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-29                      [1, 128, 56, 56]          32,768\n",
       "│    │    └─BatchNorm2d: 3-30                      [1, 128, 56, 56]          256\n",
       "│    │    └─ReLU: 3-31                             [1, 128, 56, 56]          --\n",
       "│    │    └─QuantConv2d: 3-32                      [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-34                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-35                      [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-36                      [1, 512, 28, 28]          1,024\n",
       "│    │    └─Sequential: 3-37                       [1, 512, 28, 28]          132,096\n",
       "│    │    └─ReLU: 3-38                             [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-7                             [1, 512, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-39                      [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-40                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-41                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-42                      [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-43                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-44                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-45                      [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-46                      [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-47                             [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-8                             [1, 512, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-48                      [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-49                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-50                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-51                      [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-52                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-53                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-54                      [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-55                      [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-56                             [1, 512, 28, 28]          --\n",
       "│    └─Bottleneck: 2-9                             [1, 512, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-57                      [1, 128, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-58                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-59                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-60                      [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61                      [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-62                             [1, 128, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-63                      [1, 512, 28, 28]          65,536\n",
       "│    │    └─BatchNorm2d: 3-64                      [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-65                             [1, 512, 28, 28]          --\n",
       "├─Sequential: 1-7                                  [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-10                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-66                      [1, 256, 28, 28]          131,072\n",
       "│    │    └─BatchNorm2d: 3-67                      [1, 256, 28, 28]          512\n",
       "│    │    └─ReLU: 3-68                             [1, 256, 28, 28]          --\n",
       "│    │    └─QuantConv2d: 3-69                      [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-71                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-72                      [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-73                      [1, 1024, 14, 14]         2,048\n",
       "│    │    └─Sequential: 3-74                       [1, 1024, 14, 14]         526,336\n",
       "│    │    └─ReLU: 3-75                             [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-11                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-76                      [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-77                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-78                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-79                      [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-80                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-81                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-82                      [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-83                      [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-84                             [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-12                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-85                      [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-86                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-87                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-88                      [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-89                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-90                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-91                      [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-92                      [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-93                             [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-13                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-94                      [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-95                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-96                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-97                      [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-98                      [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-99                             [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-100                     [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-101                     [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-102                            [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-14                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-103                     [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-104                     [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-105                            [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-106                     [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-107                     [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-108                            [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-109                     [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-110                     [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-111                            [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-15                            [1, 1024, 14, 14]         --\n",
       "│    │    └─QuantConv2d: 3-112                     [1, 256, 14, 14]          262,144\n",
       "│    │    └─BatchNorm2d: 3-113                     [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-114                            [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-115                     [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-116                     [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-117                            [1, 256, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-118                     [1, 1024, 14, 14]         262,144\n",
       "│    │    └─BatchNorm2d: 3-119                     [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-120                            [1, 1024, 14, 14]         --\n",
       "├─Sequential: 1-8                                  [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-16                            [1, 2048, 7, 7]           --\n",
       "│    │    └─QuantConv2d: 3-121                     [1, 512, 14, 14]          524,288\n",
       "│    │    └─BatchNorm2d: 3-122                     [1, 512, 14, 14]          1,024\n",
       "│    │    └─ReLU: 3-123                            [1, 512, 14, 14]          --\n",
       "│    │    └─QuantConv2d: 3-124                     [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-125                     [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-126                            [1, 512, 7, 7]            --\n",
       "│    │    └─QuantConv2d: 3-127                     [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-128                     [1, 2048, 7, 7]           4,096\n",
       "│    │    └─Sequential: 3-129                      [1, 2048, 7, 7]           2,101,248\n",
       "│    │    └─ReLU: 3-130                            [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-17                            [1, 2048, 7, 7]           --\n",
       "│    │    └─QuantConv2d: 3-131                     [1, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-132                     [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-133                            [1, 512, 7, 7]            --\n",
       "│    │    └─QuantConv2d: 3-134                     [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-135                     [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-136                            [1, 512, 7, 7]            --\n",
       "│    │    └─QuantConv2d: 3-137                     [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-138                     [1, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-139                            [1, 2048, 7, 7]           --\n",
       "│    └─Bottleneck: 2-18                            [1, 2048, 7, 7]           --\n",
       "│    │    └─QuantConv2d: 3-140                     [1, 512, 7, 7]            1,048,576\n",
       "│    │    └─BatchNorm2d: 3-141                     [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-142                            [1, 512, 7, 7]            --\n",
       "│    │    └─QuantConv2d: 3-143                     [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-144                     [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-145                            [1, 512, 7, 7]            --\n",
       "│    │    └─QuantConv2d: 3-146                     [1, 2048, 7, 7]           1,048,576\n",
       "│    │    └─BatchNorm2d: 3-147                     [1, 2048, 7, 7]           4,096\n",
       "│    │    └─ReLU: 3-148                            [1, 2048, 7, 7]           --\n",
       "├─QuantAdaptiveAvgPool2d: 1-9                      [1, 2048, 1, 1]           --\n",
       "│    └─TensorQuantizer: 2-19                       [1, 2048, 7, 7]           --\n",
       "├─QuantLinear: 1-10                                [1, 1000]                 2,049,000\n",
       "│    └─TensorQuantizer: 2-20                       [1, 2048]                 --\n",
       "│    └─TensorQuantizer: 2-21                       [1000, 2048]              --\n",
       "====================================================================================================\n",
       "Total params: 25,557,032\n",
       "Trainable params: 25,557,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.05\n",
       "====================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 88.91\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 89.73\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import io\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "\n",
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()\n",
    "\n",
    "from src.quantization.quantized_model import QuantizedModel\n",
    "from src.exploration.problems import LayerwiseQuantizationProblem\n",
    "\n",
    "path = 'retrained_model.m'\n",
    "\n",
    "m = models.resnet.resnet50()\n",
    "\n",
    "summary(m, (1, 3, 224, 224))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in m.named_modules():\n",
    "    if isinstance(module, quant_modules.quant_nn.TensorQuantizer):\n",
    "        module.enable_quant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=2.6387 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.2427, 1.9790](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=40.8780 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.2322, 1.5130](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=17.1855 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1967, 1.4748](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=23.5362 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 1.3518](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.downsample.0._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=40.8780 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.0.downsample.0._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 1.8782](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.2407 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 1.0187](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.0554 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.2819, 0.9823](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=18.3924 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.1.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0465, 0.7892](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=12.3442 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.2121, 0.5133](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.2407 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1932, 0.7743](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=22.2132 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer1.2.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0242, 0.8039](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=17.1643 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.2326, 0.9839](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=15.9014 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1469, 0.4567](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=19.1108 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 0.8369](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.downsample.0._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=17.1643 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.0.downsample.0._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 1.2383](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=17.5402 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1432, 0.5148](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.0974 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1468, 0.7586](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=20.3443 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.1.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0201, 0.8381](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=15.2603 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1595, 0.6490](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.1196 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1488, 0.8606](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.0873 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.2.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0196, 0.7607](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=15.6803 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1486, 0.5396](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.4843 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1421, 0.6717](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=12.0244 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer2.3.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0165, 0.6675](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=15.6432 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1813, 0.7995](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.9822 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1027, 0.5471](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.5091 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 0.8737](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.downsample.0._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=15.6432 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.0.downsample.0._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0000, 1.0368](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.7873 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1026, 0.7600](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.4076 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1058, 0.7048](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.1292 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.1.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0115, 0.9448](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=12.8433 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1134, 0.7175](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.1410 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0965, 0.5678](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.5323 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.2.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0088, 0.6072](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.3699 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1114, 0.6577](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.1862 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0944, 0.8113](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.7943 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.3.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0444, 0.5874](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=14.7458 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1173, 0.6839](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=13.0218 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0980, 0.4979](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.1815 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.4.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0110, 0.5460](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=14.9946 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1174, 0.5949](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.7968 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0945, 0.3427](256) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.6983 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer3.5.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0326, 0.5161](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=14.4017 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1321, 1.0426](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=11.6974 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0736, 0.6552](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.8149 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0307, 0.9215](2048) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.downsample.0._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=14.4017 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.0.downsample.0._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0567, 0.7500](2048) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=23.1952 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0998, 0.6408](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=14.1674 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0675, 0.5745](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.5970 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.1.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0611, 0.5613](2048) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv1._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=22.8718 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv1._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.1147, 0.8181](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv2._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=9.1926 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv2._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0539, 0.7966](512) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv3._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=10.7154 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "layer4.2.conv3._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.0510, 0.6134](2048) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "avgpool._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=131.4121 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "fc._input_quantizer: 8 bits, mod: TensorQuantizer(8bit fake per-tensor amax=6.4827 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "fc._weight_quantizer: 8 bits, mod: TensorQuantizer(8bit fake axis=0 amax=[0.4240, 1.2790](1000) calibrator=MaxCalibrator scale=1.0 quant)\n"
     ]
    }
   ],
   "source": [
    "for name, module in m.named_modules():\n",
    "    if isinstance(module, quant_modules.quant_nn.TensorQuantizer):\n",
    "        print(\"{}: {} bits, mod: {}\".format(name, module.num_bits, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0095, -0.0046,  0.0364, -0.0647,  0.0478, -0.0206,  0.0083],\n",
       "        [-0.0567,  0.0460,  0.0790, -0.1770,  0.0911,  0.0316, -0.0560],\n",
       "        [ 0.0694, -0.2692,  0.4052, -0.1330, -0.1630,  0.2209, -0.0708],\n",
       "        [ 0.0244,  0.1294, -0.6641,  1.1666, -0.9223,  0.2885, -0.0361],\n",
       "        [-0.1096,  0.3817, -0.4542, -0.1022,  0.6848, -0.5775,  0.2255],\n",
       "        [ 0.0242, -0.1777,  0.6440, -0.9113,  0.5268, -0.0485, -0.0679],\n",
       "        [ 0.0439, -0.1317,  0.0174,  0.2513, -0.3571,  0.1905, -0.0224]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "m.conv1.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorQuantizer(8bit fake axis=0 amax=[0.2427, 1.9790](64) calibrator=MaxCalibrator scale=1.0 quant)\n"
     ]
    }
   ],
   "source": [
    "print(m.conv1.weight_quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, May 10 2022, 23:46:40) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-10)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13163a71fd25ca99df19113b0b7fef1658e8dabbe29c7565da80e947514db9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
