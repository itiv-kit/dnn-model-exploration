{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization.nn.modules.tensor_quantizer import TensorQuantizer\n",
    "\n",
    "from pytorch_quantization import tensor_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc = QuantDescriptor(\n",
    "    num_bits=5,\n",
    "    fake_quant=True,\n",
    "    # axis=(1),\n",
    "    unsigned=False\n",
    "    # amax=3.0\n",
    ")\n",
    "\n",
    "quantizer = TensorQuantizer(quant_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0815 10:38:30.598164 139950796811136 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0815 10:38:30.602174 139950796811136 tensor_quantizer.py:173] Disable MaxCalibrator\n"
     ]
    }
   ],
   "source": [
    "d = torch.randn(4, 4)\n",
    "\n",
    "quantizer.enable_calib()\n",
    "quantizer.disable_quant()\n",
    "quantizer(d)\n",
    "quantizer.load_calib_amax()\n",
    "quantizer.enable_quant()\n",
    "quantizer.disable_calib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3153,  0.1733,  1.3470, -0.5235],\n",
      "        [ 0.9053, -1.4281, -0.5574, -0.7609],\n",
      "        [ 0.5443, -1.0818,  1.2443, -0.5277],\n",
      "        [ 0.6591,  1.6441,  1.9719, -0.2160]])\n",
      "tensor([[-1.3146,  0.1315,  1.3146, -0.5258],\n",
      "        [ 0.9202, -1.4461, -0.5258, -0.7888],\n",
      "        [ 0.5258, -1.0517,  1.1832, -0.5258],\n",
      "        [ 0.6573,  1.7090,  1.9719, -0.2629]])\n",
      "<class 'torch.Tensor'>\n",
      "5bit narrow fake per-tensor amax=1.9719 calibrator=MaxCalibrator scale=1.0 quant\n",
      "tensor(1.9719)\n",
      "tensor(0.1315)\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "res = quantizer(d)\n",
    "print(res)\n",
    "print(type(res))\n",
    "print(quantizer.extra_repr())\n",
    "print(quantizer.amax)\n",
    "print(quantizer.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_quantization.nn as quant_nn\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.4715,   1.1894,   1.9073,   2.6252,   3.3431],\n",
      "        [  1.3406,   5.0019,   8.6632,  12.3244,  15.9857],\n",
      "        [ -2.8714,  -6.6169, -10.3624, -14.1079, -17.8534],\n",
      "        [ -1.6520,  -5.8589, -10.0657, -14.2726, -18.4795],\n",
      "        [ -4.9389,  -8.3278, -11.7168, -15.1057, -18.4946]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.linspace(0, 10, 25).reshape( (5,5) )\n",
    "b = torch.linspace(0, 5, 5)\n",
    "d = torch.randn( (5, 5) )\n",
    "\n",
    "fc = nn.Linear(5, 5, bias=True)\n",
    "\n",
    "fc.weight = nn.Parameter(w)\n",
    "fc.bias = nn.Parameter(b)\n",
    "\n",
    "res = fc(d)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.2976,   0.5525,   0.8182,   1.1142,   1.3358],\n",
      "        [  1.2710,   4.9956,   8.7062,  12.3641,  16.1786],\n",
      "        [ -2.6660,  -6.3388, -10.0101, -13.6992, -17.3014],\n",
      "        [ -1.3826,  -5.0694,  -8.7406, -12.3886, -16.0552],\n",
      "        [ -4.6221,  -7.3014,  -9.9884, -12.6831, -15.3856]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'in_features=5, out_features=5, bias=True'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_desc = QuantDescriptor(num_bits=8, amax=30.0)\n",
    "\n",
    "quant_fc = quant_nn.Linear(5, 5, bias=True, \n",
    "    quant_desc_input=input_desc,\n",
    "    quant_desc_weight=tensor_quant.QUANT_DESC_8BIT_LINEAR_WEIGHT_PER_ROW)\n",
    "quant_fc.weight = nn.Parameter(w)\n",
    "quant_fc.bias = nn.Parameter(b)\n",
    "res = quant_fc(d)\n",
    "print(res)\n",
    "input_desc,\n",
    "quant_fc.extra_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8958,  0.7250, -0.1243, -0.4962,  0.5360],\n",
      "        [ 0.8914, -0.6906, -0.4559,  0.8301,  0.5824],\n",
      "        [ 1.0150, -1.3410, -0.9649, -0.8075, -0.2995],\n",
      "        [-0.5101, -0.7255, -0.7554, -0.7846,  0.1563],\n",
      "        [ 1.5592, -0.9597,  0.4358, -1.2826, -1.9794]])\n",
      "tensor([[-0.9449,  0.7087, -0.2362, -0.4724,  0.4724],\n",
      "        [ 0.9449, -0.7087, -0.4724,  0.9449,  0.4724],\n",
      "        [ 0.9449, -1.4173, -0.9449, -0.7087, -0.2362],\n",
      "        [-0.4724, -0.7087, -0.7087, -0.7087,  0.2362],\n",
      "        [ 1.6535, -0.9449,  0.4724, -1.1811, -1.8898]])\n",
      "tensor([[ 0.0000,  0.4167,  0.8333,  1.2500,  1.6667],\n",
      "        [ 2.0833,  2.5000,  2.9167,  3.3333,  3.7500],\n",
      "        [ 4.1667,  4.5833,  5.0000,  5.4167,  5.8333],\n",
      "        [ 6.2500,  6.6667,  7.0833,  7.5000,  7.9167],\n",
      "        [ 8.3333,  8.7500,  9.1667,  9.5833, 10.0000]])\n",
      "tensor([[ 0.0000,  0.4199,  0.8399,  1.2467,  1.6667],\n",
      "        [ 2.0965,  2.5098,  2.9232,  3.3366,  3.7500],\n",
      "        [ 4.1798,  4.5932,  5.0066,  5.4199,  5.8333],\n",
      "        [ 6.2336,  6.6699,  7.1063,  7.4803,  7.9167],\n",
      "        [ 8.3465,  8.7402,  9.1339,  9.6063, 10.0000]])\n",
      "tensor(30.)\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "print(quant_fc._input_quantizer(d))\n",
    "print(w)\n",
    "print(quant_fc._weight_quantizer(w))\n",
    "print(quant_fc._input_quantizer._get_amax(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('torch_quantization')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f13163a71fd25ca99df19113b0b7fef1658e8dabbe29c7565da80e947514db9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
