workload:
  problem:
    # problem_function: sparsity_problem
    problem_function: quantization_problem
    # problem_function: energy_aware_quant_problem

  model:
    type: deeplabv3
    weights: null

  calibration:
    samples: null # null sets samples to all
    file: './results/deeplabv3_quant_calib.pkl'
    datasets:
      calibrate:
        type: 'cityscapes'
        kind: null
        path: '/tools/datasets/cityscapes'
        sample_limit: 128  # number of validation dataset samples to test for each individual
        batch_size: 8
        randomize: True
        split: val

  exploration:
    nsga: # Setup the parameters for your nsga algorithm
      pop_size: 20
      offsprings: 20
      generations: 10
      mutation_eta: 10
      mutation_prob: 1.0
      crossover_eta: 5
      crossover_prob: 1.0
    minimum_accuracy: 0.9
    datasets:
      exploration:  
        type: 'cityscapes_weather'
        kind: null
        path: '/tools/datasets/cityscapes'
        sample_limit: 128 # number of validation dataset samples to test for each individual
        batch_size: 8
        randomize: True
        split: val
        weather_condition: rain
        alpha: 0.03
        dropsize: 0.002
        pattern: 1
        beta: 0.015
      baseline:
        type: 'cityscapes_weather'
        kind: null
        path: '/tools/datasets/cityscapes'
        sample_limit: null # number of validation dataset samples to test for each individual
        batch_size: 8
        randomize: True
        split: val
        weather_condition: rain
        alpha: 0.03
        dropsize: 0.002
        pattern: 1
        beta: 0.015
    energy_evaluation:
      dram_analysis_file: 'results/dram_accesses_deeplabv3.csv'
      input_shape: [1, 3, 2048, 1024]
    extra_args:
      # for quantization
      num_bits_upper_limit: 14
      num_bits_lower_limit: 4
      bit_weighting_function: 'bits_weighted_per_layer'
      # for sparsity
      discrete_threshold_steps: 100
      discrete_threshold_method: linear
      threshold_limit: 0.8
      block_size: [8,8]

  retraining:
    epochs: 4
    datasets:
      validation:
        type: 'cityscapes'
        kind: null
        path: '/tools/datasets/cityscapes'
        sample_limit: 25000 # number of validation dataset samples to test for each individual
        batch_size: 8
        randomize: True
        split: val
      train:
        type: 'cityscapes'
        kind: null
        path: '/tools/datasets/cityscapes/gtCoarse/train'
        total_samples: 1281167
        batch_size: 8
        sample_limit: null
        split: train

  reevaluation:
    bit_weighting_function: 'bits_weighted_per_layer'
    datasets:
      reevaluate:
        type: 'cityscapes'
        kind: null
        path: '/tools/datasets/cityscapes'
        sample_limit: null
        batch_size: 8
        randomize: True
        split: val


